{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0221ENSkillsNetwork899-2023-01-01\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Extract Transform Load (ETL) Lab**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    "-   Read CSV and JSON file types.\n",
    "-   Extract data from the above file types.\n",
    "-   Transform data.\n",
    "-   Save the transformed data in a ready-to-load format which data engineers can use to load into an RDBMS.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required modules and functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob                         # this module helps in selecting files \n",
    "import pandas as pd                 # this module helps in processing CSV files\n",
    "import xml.etree.ElementTree as ET  # this module helps in processing XML files.\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip\u001b[39;00m\n\u001b[0;32m      3\u001b[0m url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module\u001b[39m\u001b[39m%\u001b[39m\u001b[39m206/Lab\u001b[39m\u001b[39m%\u001b[39m\u001b[39m20-\u001b[39m\u001b[39m%20E\u001b[39;00m\u001b[39mxtract\u001b[39m\u001b[39m%\u001b[39m\u001b[39m20Transform\u001b[39m\u001b[39m%20Lo\u001b[39;00m\u001b[39mad/data/source.zip\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m filename \u001b[39m=\u001b[39m wget\u001b[39m.\u001b[39;49mdownload(url)\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wget.py:526\u001b[0m, in \u001b[0;36mdownload\u001b[1;34m(url, out, bar)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    525\u001b[0m     binurl \u001b[39m=\u001b[39m url\n\u001b[1;32m--> 526\u001b[0m (tmpfile, headers) \u001b[39m=\u001b[39m ulib\u001b[39m.\u001b[39;49murlretrieve(binurl, tmpfile, callback)\n\u001b[0;32m    527\u001b[0m filename \u001b[39m=\u001b[39m detect_filename(url, out, headers)\n\u001b[0;32m    528\u001b[0m \u001b[39mif\u001b[39;00m outdir:\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:241\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[39mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m url_type, path \u001b[39m=\u001b[39m _splittype(url)\n\u001b[1;32m--> 241\u001b[0m \u001b[39mwith\u001b[39;00m contextlib\u001b[39m.\u001b[39mclosing(urlopen(url, data)) \u001b[39mas\u001b[39;00m fp:\n\u001b[0;32m    242\u001b[0m     headers \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39minfo()\n\u001b[0;32m    244\u001b[0m     \u001b[39m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[39m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[39mfor\u001b[39;00m processor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_response\u001b[39m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[39m=\u001b[39m meth(req, response)\n\u001b[0;32m    527\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[39m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m code \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparent\u001b[39m.\u001b[39;49merror(\n\u001b[0;32m    635\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mhttp\u001b[39;49m\u001b[39m'\u001b[39;49m, request, response, code, msg, hdrs)\n\u001b[0;32m    637\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[39mif\u001b[39;00m http_err:\n\u001b[0;32m    562\u001b[0m     args \u001b[39m=\u001b[39m (\u001b[39mdict\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhttp_error_default\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    497\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttp_error_default\u001b[39m(\u001b[39mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(req\u001b[39m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "#!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip\n",
    "\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip\"\n",
    "\n",
    "filename = wget.download(url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pip unzip source.zip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpfile    = \"temp.tmp\"               # file used to store all extracted data\n",
    "logfile    = \"logfile.txt\"            # all event logs will be stored in this file\n",
    "targetfile = \"transformed_data.csv\"   # file where transformed data is stored"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_csv(file_to_process):\n",
    "    dataframe = pd.read_csv(file_to_process)\n",
    "    return dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_json(file_to_process):\n",
    "    dataframe = pd.read_json(file_to_process,lines=True)\n",
    "    return dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_xml(file_to_process):\n",
    "    dataframe = pd.DataFrame(columns=[\"name\", \"height\", \"weight\"])\n",
    "    tree = ET.parse(file_to_process)\n",
    "    root = tree.getroot()\n",
    "    for person in root:\n",
    "        name = person.find(\"name\").text\n",
    "        height = float(person.find(\"height\").text)\n",
    "        weight = float(person.find(\"weight\").text)\n",
    "        dataframe = dataframe.append({\"name\":name, \"height\":height, \"weight\":weight}, ignore_index=True)\n",
    "    return dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    extracted_data = pd.DataFrame(columns=['name','height','weight']) # create an empty data frame to hold extracted data\n",
    "    \n",
    "    #process all csv files\n",
    "    for csvfile in glob.glob(\"*.csv\"):\n",
    "        extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n",
    "        \n",
    "    #process all json files\n",
    "    for jsonfile in glob.glob(\"*.json\"):\n",
    "        extracted_data = extracted_data.append(extract_from_json(jsonfile), ignore_index=True)\n",
    "    \n",
    "    #process all xml files\n",
    "    for xmlfile in glob.glob(\"*.xml\"):\n",
    "        extracted_data = extracted_data.append(extract_from_xml(xmlfile), ignore_index=True)\n",
    "        \n",
    "    return extracted_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transform function does the following tasks.\n",
    "\n",
    "1.  Convert height which is in inches to millimeter\n",
    "2.  Convert weight which is in pounds to kilograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "        #Convert height which is in inches to millimeter\n",
    "        #Convert the datatype of the column into float\n",
    "        #data.height = data.height.astype(float)\n",
    "        #Convert inches to meters and round off to two decimals(one inch is 0.0254 meters)\n",
    "        data['height'] = round(data.height * 0.0254,2)\n",
    "        \n",
    "        #Convert weight which is in pounds to kilograms\n",
    "        #Convert the datatype of the column into float\n",
    "        #data.weight = data.weight.astype(float)\n",
    "        #Convert pounds to kilograms and round off to two decimals(one pound is 0.45359237 kilograms)\n",
    "        data['weight'] = round(data.weight * 0.45359237,2)\n",
    "        return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(targetfile,data_to_load):\n",
    "    data_to_load.to_csv(targetfile)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(message):\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second\n",
    "    now = datetime.now() # get current timestamp\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(\"logfile.txt\",\"a\") as f:\n",
    "        f.write(timestamp + ',' + message + '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running ETL Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log(\"ETL Job Started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log(\"Extract phase Started\")\n",
    "extracted_data = extract()\n",
    "log(\"Extract phase Ended\")\n",
    "extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log(\"Transform phase Started\")\n",
    "transformed_data = transform(extracted_data)\n",
    "log(\"Transform phase Ended\")\n",
    "transformed_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log(\"Load phase Started\")\n",
    "load(targetfile,transformed_data)\n",
    "log(\"Load phase Ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log(\"ETL Job Ended\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the example above complete the exercise below.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-01-20 15:58:13--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4249 (4.1K) [application/zip]\n",
      "Saving to: ‘datasource.zip’\n",
      "\n",
      "datasource.zip      100%[===================>]   4.15K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2021-01-20 15:58:13 (8.09 MB/s) - ‘datasource.zip’ saved [4249/4249]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  datasource.zip\n",
      "  inflating: dealership_data/used_car_prices1.csv  \n",
      "  inflating: dealership_data/used_car_prices2.csv  \n",
      "  inflating: dealership_data/used_car_prices3.csv  \n",
      "  inflating: dealership_data/used_car_prices1.json  \n",
      "  inflating: dealership_data/used_car_prices2.json  \n",
      "  inflating: dealership_data/used_car_prices3.json  \n",
      "  inflating: dealership_data/used_car_prices1.xml  \n",
      "  inflating: dealership_data/used_car_prices2.xml  \n",
      "  inflating: dealership_data/used_car_prices3.xml  \n"
     ]
    }
   ],
   "source": [
    "!unzip datasource.zip -d dealership_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `dealership_data` contains CSV, JSON, and XML files for used car data which contain features named `car_model`, `year_of_manufacture`, `price`, and `fuel`.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpfile    = \"dealership_temp.tmp\"               # file used to store all extracted data\n",
    "logfile    = \"dealership_logfile.txt\"            # all event logs will be stored in this file\n",
    "targetfile = \"dealership_transformed_data.csv\"   # file where transformed data is stored"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: CSV Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the CSV extract function below\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "    \n",
    "```\n",
    "    \n",
    "def extract_from_csv(file_to_process):\n",
    "    dataframe = pd.read_csv(file_to_process)\n",
    "    return dataframe\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: JSON Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the JSON extract function below\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "    \n",
    "```\n",
    "    \n",
    "def extract_from_json(file_to_process):\n",
    "    dataframe = pd.read_json(file_to_process,lines=True)\n",
    "    return dataframe\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: XML Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the XML extract function below, it is the same as the xml extract function above but the column names need to be renamed.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "    \n",
    "```\n",
    "    \n",
    "def extract_from_xml(file_to_process):\n",
    "    dataframe = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel'])\n",
    "    tree = ET.parse(file_to_process)\n",
    "    root = tree.getroot()\n",
    "    for person in root:\n",
    "        car_model = person.find(\"car_model\").text\n",
    "        year_of_manufacture = int(person.find(\"year_of_manufacture\").text)\n",
    "        price = float(person.find(\"price\").text)\n",
    "        fuel = person.find(\"fuel\").text\n",
    "        dataframe = dataframe.append({\"car_model\":car_model, \"year_of_manufacture\":year_of_manufacture, \"price\":price, \"fuel\":fuel}, ignore_index=True)\n",
    "    return dataframe\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Extract Function\n",
    "\n",
    "Call the specific extract functions you created above by replacing the `ADD_FUNCTION_CALL` with the proper function call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    extracted_data = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel']) # create an empty data frame to hold extracted data\n",
    "    \n",
    "    #process all csv files\n",
    "    for csvfile in glob.glob(\"dealership_data/*.csv\"):\n",
    "        extracted_data = extracted_data.append('ADD_FUNCTION_CALL', ignore_index=True)\n",
    "        \n",
    "    #process all json files\n",
    "    for jsonfile in glob.glob(\"dealership_data/*.json\"):\n",
    "        extracted_data = extracted_data.append('ADD_FUNCTION_CALL', ignore_index=True)\n",
    "    \n",
    "    #process all xml files\n",
    "    for xmlfile in glob.glob(\"dealership_data/*.xml\"):\n",
    "        extracted_data = extracted_data.append('ADD_FUNCTION_CALL', ignore_index=True)\n",
    "        \n",
    "    return extracted_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "    \n",
    "```\n",
    "    \n",
    "def extract():\n",
    "    extracted_data = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel']) # create an empty data frame to hold extracted data\n",
    "    \n",
    "    #process all csv files\n",
    "    for csvfile in glob.glob(\"dealership_data/*.csv\"):\n",
    "        extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n",
    "        \n",
    "    #process all json files\n",
    "    for jsonfile in glob.glob(\"dealership_data/*.json\"):\n",
    "        extracted_data = extracted_data.append(extract_from_json(jsonfile), ignore_index=True)\n",
    "    \n",
    "    #process all xml files\n",
    "    for xmlfile in glob.glob(\"dealership_data/*.xml\"):\n",
    "        extracted_data = extracted_data.append(extract_from_xml(xmlfile), ignore_index=True)\n",
    "        \n",
    "    return extracted_data\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Transform\n",
    "\n",
    "Round the `price` columns to 2 decimal places\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the transform function below\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "    \n",
    "```\n",
    "\n",
    "def transform(data):\n",
    "        data['price'] = round(data.price, 2)\n",
    "        return data\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the load function below\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "    \n",
    "```\n",
    "\n",
    "def load(targetfile,data_to_load):\n",
    "    data_to_load.to_csv(targetfile)  \n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: Log\n",
    "\n",
    "Make sure to change the name of the logfile to the one specified in the set paths section. Change the timestamp order to Hour-Minute-Second-Monthname-Day-Year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the log function below\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "    \n",
    "```\n",
    "\n",
    "def log(message):\n",
    "    timestamp_format = '%H:%M:%S-%h-%d-%Y' #Hour-Minute-Second-MonthName-Day-Year\n",
    "    now = datetime.now() # get current timestamp\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(\"dealership_logfile.txt\",\"a\") as f:\n",
    "        f.write(timestamp + ',' + message + '\\n') \n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running ETL Process\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8: ETL Process\n",
    "\n",
    "Run all functions to extract, transform, and load the data. Make sure to log all events using the `log` function. Place your code under each comment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log that you have started the ETL process\n",
    "\n",
    "\n",
    "# Log that you have started the Extract step\n",
    "\n",
    "# Call the Extract function\n",
    "\n",
    "# Log that you have completed the Extract step\n",
    "\n",
    "\n",
    "# Log that you have started the Transform step\n",
    "\n",
    "# Call the Transform function\n",
    "\n",
    "# Log that you have completed the Transform step\n",
    "\n",
    "\n",
    "# Log that you have started the Load step\n",
    "\n",
    "# Call the Load function\n",
    "\n",
    "# Log that you have completed the Load step\n",
    "\n",
    "\n",
    "# Log that you have completed the ETL process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "    \n",
    "```\n",
    "\n",
    "log(\"ETL Job Started\")\n",
    "\n",
    "log(\"Extract phase Started\")\n",
    "extracted_data = extract()\n",
    "log(\"Extract phase Ended\")\n",
    "\n",
    "log(\"Transform phase Started\")\n",
    "transformed_data = transform(extracted_data)\n",
    "log(\"Transform phase Ended\")\n",
    "\n",
    "log(\"Load phase Started\")\n",
    "load(targetfile,transformed_data)\n",
    "log(\"Load phase Ended\")\n",
    "\n",
    "log(\"ETL Job Ended\")\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ramesh Sannareddy\n",
    "\n",
    "Joseph Santarcangelo\n",
    "\n",
    "Azim Hirjani\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date (YYYY-MM-DD) | Version | Changed By        | Change Description                 |\n",
    "| ----------------- | ------- | ----------------- | ---------------------------------- |\n",
    "| 2020-11-25        | 0.1     | Ramesh Sannareddy | Created initial version of the lab |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Copyright © 2020 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0221ENSkillsNetwork899-2023-01-01&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork-23455645&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
